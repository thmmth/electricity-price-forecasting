{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e391835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Final dataset saved to: c:\\Users\\QT153ZL\\OneDrive - EY\\Desktop\\electricity-price-forecasting\\data\\energy_dataset.csv\n",
      "📊 DataFrame shape: (1827, 61)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>pun_Price</th>\n",
       "      <th>brent_Price</th>\n",
       "      <th>coal_Price</th>\n",
       "      <th>crude_oil_Price</th>\n",
       "      <th>gasoline_Price</th>\n",
       "      <th>ttf_gas_Price</th>\n",
       "      <th>Calabria_Load</th>\n",
       "      <th>Centre-North_Load</th>\n",
       "      <th>Centre-South_Load</th>\n",
       "      <th>...</th>\n",
       "      <th>bari_pres</th>\n",
       "      <th>bologna_pres</th>\n",
       "      <th>cagliari_pres</th>\n",
       "      <th>milano_pres</th>\n",
       "      <th>napoli_pres</th>\n",
       "      <th>palermo_pres</th>\n",
       "      <th>roma_pres</th>\n",
       "      <th>torino_pres</th>\n",
       "      <th>venezia_pres</th>\n",
       "      <th>target_pun</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>35.792118</td>\n",
       "      <td>66.3929</td>\n",
       "      <td>NaN</td>\n",
       "      <td>61.1925</td>\n",
       "      <td>1.7168</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59445.0</td>\n",
       "      <td>100236.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1028.4</td>\n",
       "      <td>1031.2</td>\n",
       "      <td>1031.1</td>\n",
       "      <td>1031.0</td>\n",
       "      <td>1028.4</td>\n",
       "      <td>1028.6</td>\n",
       "      <td>1028.8</td>\n",
       "      <td>1029.7</td>\n",
       "      <td>1031.3</td>\n",
       "      <td>45.745415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>45.745415</td>\n",
       "      <td>66.2512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>61.0050</td>\n",
       "      <td>1.7155</td>\n",
       "      <td>12.073</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84763.0</td>\n",
       "      <td>125771.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1030.5</td>\n",
       "      <td>1032.5</td>\n",
       "      <td>1031.9</td>\n",
       "      <td>1032.7</td>\n",
       "      <td>1029.5</td>\n",
       "      <td>1029.4</td>\n",
       "      <td>1029.8</td>\n",
       "      <td>1031.6</td>\n",
       "      <td>1031.9</td>\n",
       "      <td>43.938159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>43.938159</td>\n",
       "      <td>68.6226</td>\n",
       "      <td>67.5</td>\n",
       "      <td>62.8565</td>\n",
       "      <td>1.7628</td>\n",
       "      <td>12.985</td>\n",
       "      <td>NaN</td>\n",
       "      <td>85840.0</td>\n",
       "      <td>131904.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1027.8</td>\n",
       "      <td>1027.4</td>\n",
       "      <td>1030.3</td>\n",
       "      <td>1027.6</td>\n",
       "      <td>1027.8</td>\n",
       "      <td>1028.9</td>\n",
       "      <td>1027.8</td>\n",
       "      <td>1026.9</td>\n",
       "      <td>1027.3</td>\n",
       "      <td>44.208705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-04</td>\n",
       "      <td>44.208705</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69636.0</td>\n",
       "      <td>118140.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1023.1</td>\n",
       "      <td>1023.5</td>\n",
       "      <td>1025.8</td>\n",
       "      <td>1023.8</td>\n",
       "      <td>1023.5</td>\n",
       "      <td>1024.8</td>\n",
       "      <td>1023.5</td>\n",
       "      <td>1023.3</td>\n",
       "      <td>1023.2</td>\n",
       "      <td>38.060425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-05</td>\n",
       "      <td>38.060425</td>\n",
       "      <td>69.4577</td>\n",
       "      <td>NaN</td>\n",
       "      <td>63.5387</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65449.0</td>\n",
       "      <td>110105.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1022.1</td>\n",
       "      <td>1027.5</td>\n",
       "      <td>1025.8</td>\n",
       "      <td>1027.6</td>\n",
       "      <td>1023.9</td>\n",
       "      <td>1022.6</td>\n",
       "      <td>1024.6</td>\n",
       "      <td>1026.2</td>\n",
       "      <td>1028.1</td>\n",
       "      <td>39.923403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  pun_Price  brent_Price  coal_Price  crude_oil_Price  \\\n",
       "0  2020-01-01  35.792118      66.3929         NaN          61.1925   \n",
       "1  2020-01-02  45.745415      66.2512         NaN          61.0050   \n",
       "2  2020-01-03  43.938159      68.6226        67.5          62.8565   \n",
       "3  2020-01-04  44.208705          NaN         NaN              NaN   \n",
       "4  2020-01-05  38.060425      69.4577         NaN          63.5387   \n",
       "\n",
       "   gasoline_Price  ttf_gas_Price  Calabria_Load  Centre-North_Load  \\\n",
       "0          1.7168            NaN            NaN            59445.0   \n",
       "1          1.7155         12.073            NaN            84763.0   \n",
       "2          1.7628         12.985            NaN            85840.0   \n",
       "3             NaN            NaN            NaN            69636.0   \n",
       "4             NaN            NaN            NaN            65449.0   \n",
       "\n",
       "   Centre-South_Load  ...  bari_pres  bologna_pres  cagliari_pres  \\\n",
       "0           100236.0  ...     1028.4        1031.2         1031.1   \n",
       "1           125771.0  ...     1030.5        1032.5         1031.9   \n",
       "2           131904.0  ...     1027.8        1027.4         1030.3   \n",
       "3           118140.0  ...     1023.1        1023.5         1025.8   \n",
       "4           110105.0  ...     1022.1        1027.5         1025.8   \n",
       "\n",
       "   milano_pres  napoli_pres  palermo_pres  roma_pres  torino_pres  \\\n",
       "0       1031.0       1028.4        1028.6     1028.8       1029.7   \n",
       "1       1032.7       1029.5        1029.4     1029.8       1031.6   \n",
       "2       1027.6       1027.8        1028.9     1027.8       1026.9   \n",
       "3       1023.8       1023.5        1024.8     1023.5       1023.3   \n",
       "4       1027.6       1023.9        1022.6     1024.6       1026.2   \n",
       "\n",
       "   venezia_pres  target_pun  \n",
       "0        1031.3   45.745415  \n",
       "1        1031.9   43.938159  \n",
       "2        1027.3   44.208705  \n",
       "3        1023.2   38.060425  \n",
       "4        1028.1   39.923403  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === IMPORTS ===\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import os\n",
    "\n",
    "# === PATH SETUP ===\n",
    "BASE_DIR = os.path.abspath(\"..\")  # Assumes notebook is in 'notebooks/'\n",
    "CSV_PATH = os.path.join(BASE_DIR, \"data\", \"pun_target.csv\")\n",
    "DB_PATH = os.path.join(BASE_DIR, \"db\", \"data.db\")\n",
    "OUTPUT_PATH = os.path.join(BASE_DIR, \"data\", \"energy_dataset.csv\")\n",
    "\n",
    "# === LOAD TARGET (PUN) CSV ===\n",
    "df_target = pd.read_csv(CSV_PATH, delimiter=\";\", encoding=\"utf-8\")\n",
    "df_target.columns = [col.strip().lower() for col in df_target.columns]\n",
    "df_target.rename(columns={\"€/mwh\": \"target_pun\"}, inplace=True)\n",
    "df_target = df_target[[\"target_pun\"]].copy()  # preserve only target column\n",
    "\n",
    "# === CREATE FULL DATE RANGE ===\n",
    "full_dates = pd.DataFrame({\"date\": pd.date_range(start=\"2020-01-01\", end=\"2024-12-31\").date})\n",
    "\n",
    "# === LOAD DATA FROM SQLITE ===\n",
    "conn = sqlite3.connect(DB_PATH)\n",
    "\n",
    "# --- Commodity Features ---\n",
    "commodity_df = pd.read_sql(\"SELECT * FROM commodity_prices\", conn, parse_dates=[\"date\"])\n",
    "commodity_df[\"date\"] = commodity_df[\"date\"].dt.date\n",
    "commodity_pivot = commodity_df.pivot(index=\"date\", columns=\"commodity\", values=\"price\").add_suffix(\"_Price\").reset_index()\n",
    "\n",
    "# --- Load Forecast Features ---\n",
    "load_df = pd.read_sql(\"SELECT * FROM load_forecast\", conn, parse_dates=[\"date\"])\n",
    "load_df[\"date\"] = load_df[\"date\"].dt.date\n",
    "load_pivot = load_df.pivot(index=\"date\", columns=\"zone\", values=\"load_mw\").add_suffix(\"_Load\").reset_index()\n",
    "\n",
    "# --- Weather Features ---\n",
    "weather_df = pd.read_sql(\"SELECT * FROM weather_data\", conn, parse_dates=[\"time\"])\n",
    "weather_df[\"date\"] = weather_df[\"time\"].dt.date\n",
    "weather_features = [\"tavg\", \"tmin\", \"tmax\", \"wspd\", \"pres\"]\n",
    "weather_agg = weather_df.groupby([\"date\", \"city\"])[weather_features].mean().reset_index()\n",
    "weather_pivot = weather_agg.pivot(index=\"date\", columns=\"city\", values=weather_features)\n",
    "weather_pivot.columns = [f\"{city}_{feature}\" for feature, city in weather_pivot.columns]\n",
    "weather_pivot = weather_pivot.reset_index()\n",
    "\n",
    "# --- PUN Price Historical (pun_prices table) ---\n",
    "pun_df = pd.read_sql(\"SELECT * FROM pun_prices\", conn, parse_dates=[\"date\"])\n",
    "pun_df[\"date\"] = pun_df[\"date\"].dt.date\n",
    "pun_df.rename(columns={\"price\": \"pun_Price\"}, inplace=True)\n",
    "\n",
    "conn.close()\n",
    "\n",
    "# === MERGE ALL FEATURES BY DATE ===\n",
    "df = full_dates.copy()\n",
    "df = df.merge(pun_df, on=\"date\", how=\"left\")\n",
    "df = df.merge(commodity_pivot, on=\"date\", how=\"left\")\n",
    "df = df.merge(load_pivot, on=\"date\", how=\"left\")\n",
    "df = df.merge(weather_pivot, on=\"date\", how=\"left\")\n",
    "\n",
    "# === ADD TARGET COLUMN BY POSITION (not date) ===\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df_target.reset_index(drop=True, inplace=True)\n",
    "df[\"target_pun\"] = df_target[\"target_pun\"]\n",
    "\n",
    "# === SAVE FINAL DATASET TO CSV ===\n",
    "df.to_csv(OUTPUT_PATH, index=False)\n",
    "print(f\"✅ Final dataset saved to: {OUTPUT_PATH}\")\n",
    "print(\"📊 DataFrame shape:\", df.shape)\n",
    "\n",
    "# === PREVIEW ===\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ecc667e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔁 Applied forward fill to commodity price columns.\n"
     ]
    }
   ],
   "source": [
    "# === FORWARD FILL COMMODITY PRICES ===\n",
    "commodity_cols = [col for col in df.columns if col.endswith(\"_Price\")]\n",
    "df[commodity_cols] = df[commodity_cols].ffill()\n",
    "print(\"🔁 Applied forward fill to commodity price columns.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "964aaebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📉 Missing value analysis (top columns):\n",
      "                   missing_count  missing_pct\n",
      "Calabria_Load                451    24.685276\n",
      "Centre-South_Load             95     5.199781\n",
      "Italy_Load                    95     5.199781\n",
      "Centre-North_Load             95     5.199781\n",
      "North_Load                    95     5.199781\n",
      "Sardinia_Load                 95     5.199781\n",
      "Sicily_Load                   95     5.199781\n",
      "South_Load                    95     5.199781\n",
      "coal_Price                     2     0.109469\n",
      "ttf_gas_Price                  1     0.054735\n"
     ]
    }
   ],
   "source": [
    "# === ANALYSE MISSING VALUES ===\n",
    "missing_info = (\n",
    "    df.isnull().sum()\n",
    "    .to_frame(name=\"missing_count\")\n",
    "    .assign(missing_pct=lambda x: (x[\"missing_count\"] / len(df)) * 100)\n",
    "    .sort_values(\"missing_pct\", ascending=False)\n",
    ")\n",
    "\n",
    "print(\"📉 Missing value analysis (top columns):\")\n",
    "print(missing_info[missing_info[\"missing_count\"] > 0].head(20)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "682fb254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🗑️ Dropped columns with >20% missing values: ['Calabria_Load']\n"
     ]
    }
   ],
   "source": [
    "# === DROP columns with missing percentage > 20% ===\n",
    "missing_pct = df.isnull().mean() * 100\n",
    "cols_to_drop = missing_pct[missing_pct > 20].index\n",
    "\n",
    "if len(cols_to_drop) > 0:\n",
    "    df.drop(columns=cols_to_drop, inplace=True)\n",
    "    print(f\"🗑️ Dropped columns with >20% missing values: {list(cols_to_drop)}\")\n",
    "else:\n",
    "    print(\"✅ No columns with >20% missing values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0214717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📈 Created lag and rolling features for pun_Price.\n",
      "❌ Dropped 101 rows containing missing values.\n"
     ]
    }
   ],
   "source": [
    "# === CREATE TIME-BASED & LAG FEATURES ===\n",
    "if \"date\" in df.columns:\n",
    "    df[\"day_of_week\"] = pd.to_datetime(df[\"date\"]).dt.dayofweek  # 0=Monday, 6=Sunday\n",
    "    df[\"month\"] = pd.to_datetime(df[\"date\"]).dt.month\n",
    "    df[\"is_sunday_or_holiday\"] = df[\"day_of_week\"].isin([6]).astype(int)  # holiday list can be added later\n",
    "else:\n",
    "    print(\"⚠️ 'date' column not found, time features not created.\")\n",
    "\n",
    "# === CREATE LAG AND ROLLING FEATURES FOR PUN ===\n",
    "if \"pun_Price\" in df.columns:\n",
    "    df[\"pun_Price_lag1\"] = df[\"pun_Price\"].shift(1)\n",
    "    df[\"pun_Price_rolling7_mean\"] = df[\"pun_Price\"].rolling(window=7).mean()\n",
    "    df[\"pun_Price_rolling7_std\"] = df[\"pun_Price\"].rolling(window=7).std()\n",
    "    print(\"📈 Created lag and rolling features for pun_Price.\")\n",
    "else:\n",
    "    print(\"⚠️ 'pun_Price' column not found, lag features not created.\")\n",
    "\n",
    "# === DROP ROWS WITH ANY REMAINING NaNs ===\n",
    "nan_rows_before = df.isnull().any(axis=1).sum()\n",
    "df.dropna(inplace=True)\n",
    "print(f\"❌ Dropped {nan_rows_before} rows containing missing values.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0e38980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Dropped 0 rows containing missing values.\n",
      "📉 Missing value analysis (top columns):\n",
      "Empty DataFrame\n",
      "Columns: [missing_count, missing_pct]\n",
      "Index: []\n",
      "📊 DataFrame shape: (1726, 66)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>pun_Price</th>\n",
       "      <th>brent_Price</th>\n",
       "      <th>coal_Price</th>\n",
       "      <th>crude_oil_Price</th>\n",
       "      <th>gasoline_Price</th>\n",
       "      <th>ttf_gas_Price</th>\n",
       "      <th>Centre-North_Load</th>\n",
       "      <th>Centre-South_Load</th>\n",
       "      <th>Italy_Load</th>\n",
       "      <th>...</th>\n",
       "      <th>roma_pres</th>\n",
       "      <th>torino_pres</th>\n",
       "      <th>venezia_pres</th>\n",
       "      <th>target_pun</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>month</th>\n",
       "      <th>is_sunday_or_holiday</th>\n",
       "      <th>pun_Price_lag1</th>\n",
       "      <th>pun_Price_rolling7_mean</th>\n",
       "      <th>pun_Price_rolling7_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2020-01-07</td>\n",
       "      <td>52.590938</td>\n",
       "      <td>68.2700</td>\n",
       "      <td>67.50</td>\n",
       "      <td>62.5100</td>\n",
       "      <td>1.7858</td>\n",
       "      <td>11.929</td>\n",
       "      <td>87563.0</td>\n",
       "      <td>136874.0</td>\n",
       "      <td>845779.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1025.0</td>\n",
       "      <td>1026.4</td>\n",
       "      <td>1027.7</td>\n",
       "      <td>47.919989</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>39.923403</td>\n",
       "      <td>42.894166</td>\n",
       "      <td>5.591728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2020-01-08</td>\n",
       "      <td>47.919989</td>\n",
       "      <td>64.7900</td>\n",
       "      <td>67.50</td>\n",
       "      <td>59.4600</td>\n",
       "      <td>1.6676</td>\n",
       "      <td>11.964</td>\n",
       "      <td>91985.0</td>\n",
       "      <td>142641.0</td>\n",
       "      <td>900505.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1027.2</td>\n",
       "      <td>1030.2</td>\n",
       "      <td>1030.6</td>\n",
       "      <td>55.440532</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>52.590938</td>\n",
       "      <td>44.626719</td>\n",
       "      <td>4.854760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2020-01-09</td>\n",
       "      <td>55.440532</td>\n",
       "      <td>65.3377</td>\n",
       "      <td>68.95</td>\n",
       "      <td>59.5500</td>\n",
       "      <td>1.6658</td>\n",
       "      <td>12.179</td>\n",
       "      <td>94804.0</td>\n",
       "      <td>139809.0</td>\n",
       "      <td>901355.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1028.3</td>\n",
       "      <td>1026.3</td>\n",
       "      <td>1027.0</td>\n",
       "      <td>52.978107</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>47.919989</td>\n",
       "      <td>46.011736</td>\n",
       "      <td>6.372745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2020-01-10</td>\n",
       "      <td>52.978107</td>\n",
       "      <td>65.0210</td>\n",
       "      <td>70.90</td>\n",
       "      <td>59.0841</td>\n",
       "      <td>1.6687</td>\n",
       "      <td>11.940</td>\n",
       "      <td>93598.0</td>\n",
       "      <td>136292.0</td>\n",
       "      <td>902371.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1025.4</td>\n",
       "      <td>1023.6</td>\n",
       "      <td>1025.0</td>\n",
       "      <td>45.419283</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>55.440532</td>\n",
       "      <td>47.303157</td>\n",
       "      <td>6.785125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2020-01-11</td>\n",
       "      <td>45.419283</td>\n",
       "      <td>65.0210</td>\n",
       "      <td>70.90</td>\n",
       "      <td>59.0841</td>\n",
       "      <td>1.6687</td>\n",
       "      <td>11.940</td>\n",
       "      <td>72734.0</td>\n",
       "      <td>125432.0</td>\n",
       "      <td>753652.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1024.5</td>\n",
       "      <td>1028.0</td>\n",
       "      <td>1028.0</td>\n",
       "      <td>45.060714</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>52.978107</td>\n",
       "      <td>47.476097</td>\n",
       "      <td>6.708099</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          date  pun_Price  brent_Price  coal_Price  crude_oil_Price  \\\n",
       "6   2020-01-07  52.590938      68.2700       67.50          62.5100   \n",
       "7   2020-01-08  47.919989      64.7900       67.50          59.4600   \n",
       "8   2020-01-09  55.440532      65.3377       68.95          59.5500   \n",
       "9   2020-01-10  52.978107      65.0210       70.90          59.0841   \n",
       "10  2020-01-11  45.419283      65.0210       70.90          59.0841   \n",
       "\n",
       "    gasoline_Price  ttf_gas_Price  Centre-North_Load  Centre-South_Load  \\\n",
       "6           1.7858         11.929            87563.0           136874.0   \n",
       "7           1.6676         11.964            91985.0           142641.0   \n",
       "8           1.6658         12.179            94804.0           139809.0   \n",
       "9           1.6687         11.940            93598.0           136292.0   \n",
       "10          1.6687         11.940            72734.0           125432.0   \n",
       "\n",
       "    Italy_Load  ...  roma_pres  torino_pres  venezia_pres  target_pun  \\\n",
       "6     845779.0  ...     1025.0       1026.4        1027.7   47.919989   \n",
       "7     900505.0  ...     1027.2       1030.2        1030.6   55.440532   \n",
       "8     901355.0  ...     1028.3       1026.3        1027.0   52.978107   \n",
       "9     902371.0  ...     1025.4       1023.6        1025.0   45.419283   \n",
       "10    753652.0  ...     1024.5       1028.0        1028.0   45.060714   \n",
       "\n",
       "    day_of_week  month  is_sunday_or_holiday  pun_Price_lag1  \\\n",
       "6             1      1                     0       39.923403   \n",
       "7             2      1                     0       52.590938   \n",
       "8             3      1                     0       47.919989   \n",
       "9             4      1                     0       55.440532   \n",
       "10            5      1                     0       52.978107   \n",
       "\n",
       "    pun_Price_rolling7_mean  pun_Price_rolling7_std  \n",
       "6                 42.894166                5.591728  \n",
       "7                 44.626719                4.854760  \n",
       "8                 46.011736                6.372745  \n",
       "9                 47.303157                6.785125  \n",
       "10                47.476097                6.708099  \n",
       "\n",
       "[5 rows x 66 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === DROP ROWS WITH ANY REMAINING NaNs ===\n",
    "nan_rows_before = df.isnull().any(axis=1).sum()\n",
    "df.dropna(inplace=True)\n",
    "print(f\"❌ Dropped {nan_rows_before} rows containing missing values.\")\n",
    "\n",
    "# === ANALYSE REMAINING MISSING VALUES ===\n",
    "missing_info = (\n",
    "    df.isnull().sum()\n",
    "    .to_frame(name=\"missing_count\")\n",
    "    .assign(missing_pct=lambda x: (x[\"missing_count\"] / len(df)) * 100)\n",
    "    .sort_values(\"missing_pct\", ascending=False)\n",
    ")\n",
    "\n",
    "print(\"📉 Missing value analysis (top columns):\")\n",
    "print(missing_info[missing_info[\"missing_count\"] > 0].head(20))\n",
    "\n",
    "# === PREVIEW ===\n",
    "print(\"📊 DataFrame shape:\", df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c421bccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# === CORRELATION MATRIX ===\n",
    "correlation_matrix = df.corr(numeric_only=True)\n",
    "\n",
    "# === HEATMAP PLOT ===\n",
    "plt.figure(figsize=(16, 12))\n",
    "sns.heatmap(correlation_matrix, cmap=\"coolwarm\", center=0, annot=False)\n",
    "plt.title(\"🔍 Correlation Matrix\", fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# === CORRELATION WITH TARGET (ORDERED) ===\n",
    "target_corr = (\n",
    "    correlation_matrix[\"target_pun\"]\n",
    "    .drop(\"target_pun\")  # Remove self-correlation\n",
    "    .sort_values(ascending=False)\n",
    ")\n",
    "\n",
    "print(\"📈 Correlation with target_pun (descending order):\")\n",
    "print(target_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2d81581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Features dataset saved to: c:\\Users\\QT153ZL\\OneDrive - EY\\Desktop\\electricity-price-forecasting\\data\\total_pun_model_features.csv\n",
      "📊 Top relevant features correlated with target_pun:\n",
      "pun_Price                  0.980403\n",
      "pun_Price_rolling7_mean    0.972154\n",
      "pun_Price_lag1             0.964796\n",
      "ttf_gas_Price              0.961877\n",
      "coal_Price                 0.846286\n",
      "pun_Price_rolling7_std     0.816107\n",
      "brent_Price                0.654975\n",
      "crude_oil_Price            0.643692\n",
      "gasoline_Price             0.563898\n",
      "Centre-South_Load          0.373326\n",
      "Sardinia_Load              0.307260\n",
      "napoli_tmin                0.229452\n",
      "month                      0.207687\n",
      "bari_tmin                  0.206072\n",
      "South_Load                -0.214056\n",
      "Name: target_pun, dtype: float64\n",
      "✅ Relevant features dataset saved to: c:\\Users\\QT153ZL\\OneDrive - EY\\Desktop\\electricity-price-forecasting\\data\\pun_model_features.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# === SAVE TO CSV ===\n",
    "BASE_DIR = os.path.abspath(\"..\")\n",
    "OUTPUT_PATH = os.path.join(BASE_DIR, \"data\", \"total_pun_model_features.csv\")\n",
    "df.to_csv(OUTPUT_PATH, index=False)\n",
    "\n",
    "print(f\"✅ Features dataset saved to: {OUTPUT_PATH}\")\n",
    "\n",
    "# === SELECT MOST RELEVANT FEATURES BASED ON CORRELATION WITH TARGET ===\n",
    "correlation_matrix = df.corr(numeric_only=True)\n",
    "target_corr = correlation_matrix[\"target_pun\"].drop(\"target_pun\")  # exclude self-correlation\n",
    "\n",
    "# Sort by absolute correlation and filter by threshold (e.g., > 0.2)\n",
    "relevant_features = target_corr[abs(target_corr) > 0.2].sort_values(ascending=False)\n",
    "\n",
    "print(\"📊 Top relevant features correlated with target_pun:\")\n",
    "print(relevant_features)\n",
    "\n",
    "# Add 'date' to selected columns\n",
    "selected_columns = [\"date\"] + relevant_features.index.tolist() + [\"target_pun\"]\n",
    "df_selected = df[selected_columns].copy()\n",
    "\n",
    "# === SAVE TO CSV ===\n",
    "BASE_DIR = os.path.abspath(\"..\")\n",
    "OUTPUT_PATH = os.path.join(BASE_DIR, \"data\", \"pun_model_features.csv\")\n",
    "df_selected.to_csv(OUTPUT_PATH, index=False)\n",
    "\n",
    "print(f\"✅ Relevant features dataset saved to: {OUTPUT_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50cfd2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Imports ===\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import sqlite3\n",
    "\n",
    "# === A. Generic True vs Predicted plot with image saving ===\n",
    "def plot_predictions(y_true, y_pred, model_name=\"Model\", label=\"\", save=True, image_format=\"png\"):\n",
    "    \"\"\"Plot for general models (e.g. tree-based). Saves image and returns its relative path.\"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import os\n",
    "    import numpy as np\n",
    "\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.plot(y_true.values, label=\"True\", linewidth=2)\n",
    "    plt.plot(y_pred, label=\"Predicted\", linestyle=\"--\", linewidth=2)\n",
    "    plt.title(f\"{model_name} - True vs Predicted {label}\")\n",
    "    plt.xlabel(\"Samples\")\n",
    "    plt.ylabel(\"PUN €/MWh\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # ✅ Compatibile con notebook\n",
    "    notebook_dir = os.path.abspath(\"\")\n",
    "    image_dir = os.path.abspath(os.path.join(notebook_dir, \"..\", \"images\"))\n",
    "    os.makedirs(image_dir, exist_ok=True)\n",
    "\n",
    "    filename = f\"{model_name}.{image_format}\"\n",
    "    image_path = os.path.join(image_dir, filename)\n",
    "\n",
    "    if save:\n",
    "        plt.savefig(image_path)\n",
    "        print(f\"📸 Plot salvato: {image_path}\")\n",
    "\n",
    "    plt.close()\n",
    "\n",
    "    # ✅ Percorso relativo per essere compatibile con Streamlit Cloud\n",
    "    return os.path.join(\"images\", filename).replace(\"\\\\\", \"/\")\n",
    "\n",
    "\n",
    "# === B. True vs Predicted plot for linear models (Lasso, Ridge, SVR) ===\n",
    "def plot_predictions_lm(y_true, y_pred, model_name=\"Model\", label=\"\", save=True, image_format=\"png\"):\n",
    "    \"\"\"Plot specifically designed for linear models. Also saves image and returns its relative path.\"\"\"\n",
    "    import os\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    y_true_array = y_true.values if hasattr(y_true, \"values\") else np.array(y_true)\n",
    "\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.plot(y_true_array, label=\"True\", linewidth=2)\n",
    "    plt.plot(y_pred, label=\"Predicted\", linestyle=\"--\", linewidth=2)\n",
    "    plt.title(f\"{model_name} - True vs Predicted {label}\")\n",
    "    plt.xlabel(\"Samples\")\n",
    "    plt.ylabel(\"PUN €/MWh\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # ✅ Path compatibile con notebook\n",
    "    base_dir = os.path.abspath(\"\")  # equivale a os.getcwd() nel notebook\n",
    "    image_dir = os.path.abspath(os.path.join(base_dir, \"..\", \"images\"))\n",
    "    os.makedirs(image_dir, exist_ok=True)\n",
    "\n",
    "    filename = f\"{model_name}.{image_format}\"\n",
    "    image_path = os.path.join(image_dir, filename)\n",
    "\n",
    "    if save:\n",
    "        plt.savefig(image_path)\n",
    "        print(f\"📸 Plot salvato: {image_path}\")\n",
    "\n",
    "    plt.close()\n",
    "\n",
    "    # ✅ Percorso relativo per salvataggio nel database o visualizzazione\n",
    "    return os.path.join(\"images\", filename).replace(\"\\\\\", \"/\")\n",
    "\n",
    "\n",
    "# === Model evaluation ===\n",
    "def evaluate(y_true, y_pred, model_name=\"Model\", label=\"\"):\n",
    "    \"\"\"Computes MAE, RMSE and R². Prints results and returns them as dictionary.\"\"\"\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "    print(f\"📊 {model_name} Evaluation {label}\")\n",
    "    print(f\"MAE:  {mae:.4f} €/MWh\")\n",
    "    print(f\"RMSE: {rmse:.4f} €/MWh\")\n",
    "    print(f\"R²:   {r2:.4f}\\n\")\n",
    "\n",
    "    return {\"MAE\": mae, \"RMSE\": rmse, \"R2\": r2}\n",
    "\n",
    "# === Save results to SQLite ===\n",
    "def save_model_results_to_db(model_name, val_metrics, test_metrics, image_path):\n",
    "    \"\"\"\n",
    "    Saves model evaluation metrics and plot image path into the 'model_results' table in data.db.\n",
    "\n",
    "    Args:\n",
    "        model_name (str): Name of the model (e.g. 'LassoCV')\n",
    "        val_metrics (dict): Dictionary with validation metrics (MAE, RMSE, R²)\n",
    "        test_metrics (dict): Dictionary with test metrics (MAE, RMSE, R²)\n",
    "        image_path (str): Absolute path of the saved prediction plot\n",
    "    \"\"\"\n",
    "    db_path = os.path.abspath(os.path.join(\"..\", \"db\", \"data.db\"))\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Create table if it does not exist\n",
    "    cursor.execute(\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS model_results (\n",
    "            model_name TEXT PRIMARY KEY,\n",
    "            val_mae REAL,\n",
    "            val_rmse REAL,\n",
    "            val_r2 REAL,\n",
    "            test_mae REAL,\n",
    "            test_rmse REAL,\n",
    "            test_r2 REAL,\n",
    "            image_path TEXT\n",
    "        )\n",
    "    \"\"\")\n",
    "\n",
    "    # Insert or update model results\n",
    "    cursor.execute(\"\"\"\n",
    "        INSERT OR REPLACE INTO model_results (\n",
    "            model_name, val_mae, val_rmse, val_r2,\n",
    "            test_mae, test_rmse, test_r2, image_path\n",
    "        ) VALUES (?, ?, ?, ?, ?, ?, ?, ?)\n",
    "    \"\"\", (\n",
    "        model_name,\n",
    "        val_metrics[\"MAE\"], val_metrics[\"RMSE\"], val_metrics[\"R2\"],\n",
    "        test_metrics[\"MAE\"], test_metrics[\"RMSE\"], test_metrics[\"R2\"],\n",
    "        image_path\n",
    "    ))\n",
    "\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "    print(f\"✅ Results saved for {model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c2c978c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n",
      "✅ Best hyperparameters:\n",
      "{'random_strength': 0.5, 'learning_rate': 0.05, 'l2_leaf_reg': 1, 'iterations': 300, 'depth': 4, 'border_count': 64, 'bagging_temperature': 0}\n",
      "\n",
      "📊 CatBoostRegressor Evaluation (Validation)\n",
      "MAE:  10.2533 €/MWh\n",
      "RMSE: 13.4251 €/MWh\n",
      "R²:   0.7312\n",
      "\n",
      "📊 CatBoostRegressor Evaluation (Test)\n",
      "MAE:  10.4217 €/MWh\n",
      "RMSE: 12.8206 €/MWh\n",
      "R²:   0.6470\n",
      "\n",
      "📸 Plot salvato: c:\\Users\\QT153ZL\\OneDrive - EY\\Desktop\\electricity-price-forecasting\\images\\CatBoostRegressor.png\n",
      "✅ Results saved for CatBoostRegressor\n"
     ]
    }
   ],
   "source": [
    "# === IMPORTS ===\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# === 1. Parse 'date' column ===\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "\n",
    "# === 2. Temporal split: Train (<=2022), Validation (2023), Test (2024) ===\n",
    "train_df = df[df[\"date\"].dt.year <= 2022].copy()\n",
    "val_df   = df[df[\"date\"].dt.year == 2023].copy()\n",
    "test_df  = df[df[\"date\"].dt.year == 2024].copy()\n",
    "\n",
    "X_train = train_df.drop(columns=[\"target_pun\", \"date\"])\n",
    "y_train = train_df[\"target_pun\"]\n",
    "X_val   = val_df.drop(columns=[\"target_pun\", \"date\"])\n",
    "y_val   = val_df[\"target_pun\"]\n",
    "X_test  = test_df.drop(columns=[\"target_pun\", \"date\"])\n",
    "y_test  = test_df[\"target_pun\"]\n",
    "\n",
    "# === 3. Define hyperparameter search space ===\n",
    "param_dist = {\n",
    "    \"iterations\": [300, 500, 800],\n",
    "    \"learning_rate\": [0.01, 0.03, 0.05],\n",
    "    \"depth\": [4, 6, 8],\n",
    "    \"l2_leaf_reg\": [1, 3, 5, 7],\n",
    "    \"bagging_temperature\": [0, 0.5, 1, 2],\n",
    "    \"random_strength\": [0.5, 1, 2],\n",
    "    \"border_count\": [32, 64, 128]\n",
    "}\n",
    "\n",
    "# === 4. Initialize base CatBoost model ===\n",
    "base_cat = CatBoostRegressor(\n",
    "    loss_function=\"RMSE\",\n",
    "    verbose=0,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# === 5. RandomizedSearchCV for hyperparameter tuning ===\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=base_cat,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=30,\n",
    "    scoring=\"neg_mean_absolute_error\",\n",
    "    cv=3,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# === 6. Train model on training set ===\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# === 7. Extract best model and print best parameters ===\n",
    "best_cat = random_search.best_estimator_\n",
    "print(\"✅ Best hyperparameters:\")\n",
    "print(random_search.best_params_)\n",
    "print()\n",
    "\n",
    "# === 8. Make predictions ===\n",
    "y_val_pred  = best_cat.predict(X_val)\n",
    "y_test_pred = best_cat.predict(X_test)\n",
    "\n",
    "# === 9. Evaluate and visualize results ===\n",
    "val_metrics  = evaluate(y_val, y_val_pred, model_name=\"CatBoostRegressor\", label=\"(Validation)\")\n",
    "test_metrics = evaluate(y_test, y_test_pred, model_name=\"CatBoostRegressor\", label=\"(Test)\")\n",
    "image_path   = plot_predictions(y_test, y_test_pred, model_name=\"CatBoostRegressor\", label=\"(Test)\")\n",
    "\n",
    "# === 10. Save results to database ===\n",
    "save_model_results_to_db(\"CatBoostRegressor\", val_metrics, test_metrics, image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "56d9941a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Best alpha: 1.93070\n",
      "\n",
      "📊 LassoCV Evaluation (Validation)\n",
      "MAE:  9.8667 €/MWh\n",
      "RMSE: 12.7032 €/MWh\n",
      "R²:   0.7594\n",
      "\n",
      "📊 LassoCV Evaluation (Test)\n",
      "MAE:  7.9504 €/MWh\n",
      "RMSE: 10.6331 €/MWh\n",
      "R²:   0.7572\n",
      "\n",
      "📸 Plot salvato: c:\\Users\\QT153ZL\\OneDrive - EY\\Desktop\\electricity-price-forecasting\\images\\LassoCV.png\n",
      "✅ Results saved for LassoCV\n"
     ]
    }
   ],
   "source": [
    "# === IMPORTS ===\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# === 1. Parse 'date' column ===\n",
    "df_selected[\"date\"] = pd.to_datetime(df_selected[\"date\"])\n",
    "\n",
    "# === 2. Temporal split: Train (<=2022), Validation (2023), Test (2024) ===\n",
    "train_df = df_selected[df_selected[\"date\"].dt.year <= 2022].copy()\n",
    "val_df   = df_selected[df_selected[\"date\"].dt.year == 2023].copy()\n",
    "test_df  = df_selected[df_selected[\"date\"].dt.year == 2024].copy()\n",
    "\n",
    "X_train = train_df.drop(columns=[\"target_pun\", \"date\"])\n",
    "y_train = train_df[\"target_pun\"]\n",
    "X_val   = val_df.drop(columns=[\"target_pun\", \"date\"])\n",
    "y_val   = val_df[\"target_pun\"]\n",
    "X_test  = test_df.drop(columns=[\"target_pun\", \"date\"])\n",
    "y_test  = test_df[\"target_pun\"]\n",
    "\n",
    "# === 3. Feature scaling ===\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled   = scaler.transform(X_val)\n",
    "X_test_scaled  = scaler.transform(X_test)\n",
    "\n",
    "# === 4. LassoCV: cross-validated alpha selection ===\n",
    "lasso_cv_model = LassoCV(\n",
    "    alphas=np.logspace(-4, 1, 50),  # search alpha from 0.0001 to 10\n",
    "    cv=5,\n",
    "    max_iter=10000,\n",
    "    random_state=42\n",
    ")\n",
    "lasso_cv_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# === 5. Best alpha found ===\n",
    "print(f\"✅ Best alpha: {lasso_cv_model.alpha_:.5f}\\n\")\n",
    "\n",
    "# === 6. Predictions ===\n",
    "y_val_pred  = lasso_cv_model.predict(X_val_scaled)\n",
    "y_test_pred = lasso_cv_model.predict(X_test_scaled)\n",
    "\n",
    "# === 7. Evaluation & visualization ===\n",
    "val_metrics  = evaluate(y_val, y_val_pred, model_name=\"LassoCV\", label=\"(Validation)\")\n",
    "test_metrics = evaluate(y_test, y_test_pred, model_name=\"LassoCV\", label=\"(Test)\")\n",
    "image_path   = plot_predictions_lm(y_test, y_test_pred, model_name=\"LassoCV\", label=\"(Test)\")\n",
    "\n",
    "# === 8. Save results to database ===\n",
    "save_model_results_to_db(\"LassoCV\", val_metrics, test_metrics, image_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e74098a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001498 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12414\n",
      "[LightGBM] [Info] Number of data points in the train set: 1030, number of used features: 64\n",
      "[LightGBM] [Info] Start training from score 153.102226\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "✅ Best hyperparameters:\n",
      "{'subsample': 1.0, 'reg_lambda': 0.1, 'reg_alpha': 0.1, 'n_estimators': 1000, 'min_child_samples': 10, 'max_depth': 8, 'learning_rate': 0.01, 'colsample_bytree': 1.0}\n",
      "\n",
      "📊 LGBMRegressor Evaluation (Validation)\n",
      "MAE:  12.4961 €/MWh\n",
      "RMSE: 16.0441 €/MWh\n",
      "R²:   0.6161\n",
      "\n",
      "📊 LGBMRegressor Evaluation (Test)\n",
      "MAE:  9.6898 €/MWh\n",
      "RMSE: 12.5695 €/MWh\n",
      "R²:   0.6607\n",
      "\n",
      "📸 Plot salvato: c:\\Users\\QT153ZL\\OneDrive - EY\\Desktop\\electricity-price-forecasting\\images\\LGBMRegressor.png\n",
      "✅ Results saved for LGBMRegressor\n"
     ]
    }
   ],
   "source": [
    "# === IMPORTS ===\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV, TimeSeriesSplit\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# === 1. Parse 'date' column ===\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "\n",
    "# === 2. Temporal split: Train (<=2022), Validation (2023), Test (2024) ===\n",
    "train_df = df[df[\"date\"].dt.year <= 2022].copy()\n",
    "val_df   = df[df[\"date\"].dt.year == 2023].copy()\n",
    "test_df  = df[df[\"date\"].dt.year == 2024].copy()\n",
    "\n",
    "X_train = train_df.drop(columns=[\"target_pun\", \"date\"])\n",
    "y_train = train_df[\"target_pun\"]\n",
    "X_val   = val_df.drop(columns=[\"target_pun\", \"date\"])\n",
    "y_val   = val_df[\"target_pun\"]\n",
    "X_test  = test_df.drop(columns=[\"target_pun\", \"date\"])\n",
    "y_test  = test_df[\"target_pun\"]\n",
    "\n",
    "# === 3. Hyperparameter grid for RandomizedSearchCV ===\n",
    "param_grid = {\n",
    "    \"n_estimators\": [300, 500, 800, 1000],\n",
    "    \"learning_rate\": [0.01, 0.03, 0.05, 0.1],\n",
    "    \"max_depth\": [4, 6, 8, 10],\n",
    "    \"min_child_samples\": [10, 20, 30],\n",
    "    \"subsample\": [0.6, 0.8, 1.0],\n",
    "    \"colsample_bytree\": [0.6, 0.8, 1.0],\n",
    "    \"reg_alpha\": [0, 0.1, 0.5],\n",
    "    \"reg_lambda\": [0, 0.1, 0.5]\n",
    "}\n",
    "\n",
    "# === 4. Base model ===\n",
    "base_model = LGBMRegressor(random_state=42)\n",
    "\n",
    "# === 5. Time series cross-validation ===\n",
    "tscv = TimeSeriesSplit(n_splits=3)\n",
    "\n",
    "# === 6. Hyperparameter tuning ===\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=base_model,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=30,\n",
    "    scoring=\"neg_mean_absolute_error\",\n",
    "    cv=tscv,\n",
    "    verbose=1,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# === 7. Fit on training set only ===\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# === 8. Best model selected ===\n",
    "best_lgbm = random_search.best_estimator_\n",
    "print(\"✅ Best hyperparameters:\")\n",
    "print(random_search.best_params_)\n",
    "print()\n",
    "\n",
    "# === 9. Predictions on validation and test sets ===\n",
    "y_val_pred  = best_lgbm.predict(X_val)\n",
    "y_test_pred = best_lgbm.predict(X_test)\n",
    "\n",
    "# === 10. Evaluation and saving ===\n",
    "val_metrics  = evaluate(y_val, y_val_pred, model_name=\"LGBMRegressor\", label=\"(Validation)\")\n",
    "test_metrics = evaluate(y_test, y_test_pred, model_name=\"LGBMRegressor\", label=\"(Test)\")\n",
    "image_path   = plot_predictions(y_test, y_test_pred, model_name=\"LGBMRegressor\", label=\"(Test)\")\n",
    "save_model_results_to_db(\"LGBMRegressor\", val_metrics, test_metrics, image_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9b267028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 RandomForestRegressor Evaluation (Validation)\n",
      "MAE:  15.2251 €/MWh\n",
      "RMSE: 18.5005 €/MWh\n",
      "R²:   0.4896\n",
      "\n",
      "📊 RandomForestRegressor Evaluation (Test)\n",
      "MAE:  12.6478 €/MWh\n",
      "RMSE: 15.3200 €/MWh\n",
      "R²:   0.4959\n",
      "\n",
      "📸 Plot salvato: c:\\Users\\QT153ZL\\OneDrive - EY\\Desktop\\electricity-price-forecasting\\images\\RandomForestRegressor.png\n",
      "✅ Results saved for RandomForestRegressor\n"
     ]
    }
   ],
   "source": [
    "# === IMPORTS ===\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# === 1. Parse 'date' column ===\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "\n",
    "# === 2. Temporal split: Train (<=2022), Validation (2023), Test (2024) ===\n",
    "train_df = df[df[\"date\"].dt.year <= 2022].copy()\n",
    "val_df   = df[df[\"date\"].dt.year == 2023].copy()\n",
    "test_df  = df[df[\"date\"].dt.year == 2024].copy()\n",
    "\n",
    "X_train = train_df.drop(columns=[\"target_pun\", \"date\"])\n",
    "y_train = train_df[\"target_pun\"]\n",
    "X_val   = val_df.drop(columns=[\"target_pun\", \"date\"])\n",
    "y_val   = val_df[\"target_pun\"]\n",
    "X_test  = test_df.drop(columns=[\"target_pun\", \"date\"])\n",
    "y_test  = test_df[\"target_pun\"]\n",
    "\n",
    "# === 3. Initialize and train Random Forest model ===\n",
    "rf_model = RandomForestRegressor(\n",
    "    n_estimators=300,\n",
    "    max_depth=10,\n",
    "    random_state=42,\n",
    "    n_jobs=-1  # Use all available CPU cores\n",
    ")\n",
    "\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# === 4. Predictions on validation and test sets ===\n",
    "y_val_pred  = rf_model.predict(X_val)\n",
    "y_test_pred = rf_model.predict(X_test)\n",
    "\n",
    "# === 5. Evaluation and saving ===\n",
    "val_metrics  = evaluate(y_val, y_val_pred, model_name=\"RandomForestRegressor\", label=\"(Validation)\")\n",
    "test_metrics = evaluate(y_test, y_test_pred, model_name=\"RandomForestRegressor\", label=\"(Test)\")\n",
    "image_path   = plot_predictions(y_test, y_test_pred, model_name=\"RandomForestRegressor\", label=\"(Test)\")\n",
    "save_model_results_to_db(\"RandomForestRegressor\", val_metrics, test_metrics, image_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c44c0f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Best alpha (refined): 6.36364\n",
      "\n",
      "📊 RidgeCV Evaluation (Validation)\n",
      "MAE:  9.8970 €/MWh\n",
      "RMSE: 12.8352 €/MWh\n",
      "R²:   0.7543\n",
      "\n",
      "📊 RidgeCV Evaluation (Test)\n",
      "MAE:  8.8277 €/MWh\n",
      "RMSE: 12.4596 €/MWh\n",
      "R²:   0.6666\n",
      "\n",
      "📸 Plot salvato: c:\\Users\\QT153ZL\\OneDrive - EY\\Desktop\\electricity-price-forecasting\\images\\RidgeCV.png\n",
      "✅ Results saved for RidgeCV\n"
     ]
    }
   ],
   "source": [
    "# === IMPORTS ===\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# === 1. Parse 'date' column ===\n",
    "df_selected[\"date\"] = pd.to_datetime(df_selected[\"date\"])\n",
    "\n",
    "# === 2. Temporal split: Train (<=2022), Validation (2023), Test (2024) ===\n",
    "train_df = df_selected[df_selected[\"date\"].dt.year <= 2022].copy()\n",
    "val_df   = df_selected[df_selected[\"date\"].dt.year == 2023].copy()\n",
    "test_df  = df_selected[df_selected[\"date\"].dt.year == 2024].copy()\n",
    "\n",
    "X_train = train_df.drop(columns=[\"target_pun\", \"date\"])\n",
    "y_train = train_df[\"target_pun\"]\n",
    "X_val   = val_df.drop(columns=[\"target_pun\", \"date\"])\n",
    "y_val   = val_df[\"target_pun\"]\n",
    "X_test  = test_df.drop(columns=[\"target_pun\", \"date\"])\n",
    "y_test  = test_df[\"target_pun\"]\n",
    "\n",
    "# === 3. Prepare validation tuning set (Train + Validation) ===\n",
    "X_tune = pd.concat([X_train, X_val])\n",
    "y_tune = pd.concat([y_train, y_val])\n",
    "\n",
    "# === 4. Define alpha search space and pipeline (scaling + RidgeCV) ===\n",
    "ridge_alphas_fine = np.linspace(1, 10, 100)\n",
    "ridge_pipeline = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"ridge\", RidgeCV(alphas=ridge_alphas_fine, scoring=\"neg_mean_absolute_error\", cv=5))\n",
    "])\n",
    "\n",
    "# === 5. Fit model on training + validation set ===\n",
    "ridge_pipeline.fit(X_tune, y_tune)\n",
    "best_alpha = ridge_pipeline.named_steps[\"ridge\"].alpha_\n",
    "print(f\"✅ Best alpha (refined): {best_alpha:.5f}\\n\")\n",
    "\n",
    "# === 6. Predictions on validation and test sets ===\n",
    "y_val_pred  = ridge_pipeline.predict(X_val)\n",
    "y_test_pred = ridge_pipeline.predict(X_test)\n",
    "\n",
    "# === 7. Evaluation and saving ===\n",
    "val_metrics  = evaluate(y_val, y_val_pred, model_name=\"RidgeCV\", label=\"(Validation)\")\n",
    "test_metrics = evaluate(y_test, y_test_pred, model_name=\"RidgeCV\", label=\"(Test)\")\n",
    "image_path   = plot_predictions_lm(y_test, y_test_pred, model_name=\"RidgeCV\", label=\"(Test)\")\n",
    "save_model_results_to_db(\"RidgeCV\", val_metrics, test_metrics, image_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ceb4875d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "✅ Best hyperparameters:\n",
      "{'gamma': 0.01, 'epsilon': 0.01, 'C': 100}\n",
      "\n",
      "📊 SVR Evaluation (Validation)\n",
      "MAE:  10.8082 €/MWh\n",
      "RMSE: 13.7728 €/MWh\n",
      "R²:   0.7171\n",
      "\n",
      "📊 SVR Evaluation (Test)\n",
      "MAE:  9.4015 €/MWh\n",
      "RMSE: 12.1354 €/MWh\n",
      "R²:   0.6837\n",
      "\n",
      "📸 Plot salvato: c:\\Users\\QT153ZL\\OneDrive - EY\\Desktop\\electricity-price-forecasting\\images\\SVR.png\n",
      "✅ Results saved for SVR\n"
     ]
    }
   ],
   "source": [
    "# === IMPORTS ===\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# === 1. Parse 'date' column ===\n",
    "df_selected[\"date\"] = pd.to_datetime(df_selected[\"date\"])\n",
    "\n",
    "# === 2. Temporal split: Train (<=2022), Validation (2023), Test (2024) ===\n",
    "train_df = df_selected[df_selected[\"date\"].dt.year <= 2022].copy()\n",
    "val_df   = df_selected[df_selected[\"date\"].dt.year == 2023].copy()\n",
    "test_df  = df_selected[df_selected[\"date\"].dt.year == 2024].copy()\n",
    "\n",
    "X_train = train_df.drop(columns=[\"target_pun\", \"date\"])\n",
    "y_train = train_df[\"target_pun\"]\n",
    "X_val   = val_df.drop(columns=[\"target_pun\", \"date\"])\n",
    "y_val   = val_df[\"target_pun\"]\n",
    "X_test  = test_df.drop(columns=[\"target_pun\", \"date\"])\n",
    "y_test  = test_df[\"target_pun\"]\n",
    "\n",
    "# === 3. Feature scaling ===\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled   = scaler.transform(X_val)\n",
    "X_test_scaled  = scaler.transform(X_test)\n",
    "\n",
    "# === 4. Hyperparameter tuning via RandomizedSearchCV ===\n",
    "param_grid = {\n",
    "    \"C\": [0.1, 1, 10, 100, 500],\n",
    "    \"epsilon\": [0.01, 0.05, 0.1, 0.5, 1],\n",
    "    \"gamma\": [\"scale\", \"auto\", 0.01, 0.1, 1]\n",
    "}\n",
    "\n",
    "svr = SVR(kernel=\"rbf\")\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=svr,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=20,\n",
    "    scoring=\"neg_mean_absolute_error\",\n",
    "    cv=3,\n",
    "    verbose=1,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# === 5. Fit model on training set only ===\n",
    "random_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# === 6. Retrieve best model ===\n",
    "best_svr = random_search.best_estimator_\n",
    "print(\"✅ Best hyperparameters:\")\n",
    "print(random_search.best_params_)\n",
    "print()\n",
    "\n",
    "# === 7. Predict on validation and test sets ===\n",
    "y_val_pred  = best_svr.predict(X_val_scaled)\n",
    "y_test_pred = best_svr.predict(X_test_scaled)\n",
    "\n",
    "# === 8. Evaluate and save results ===\n",
    "val_metrics  = evaluate(y_val, y_val_pred, model_name=\"SVR\", label=\"(Validation)\")\n",
    "test_metrics = evaluate(y_test, y_test_pred, model_name=\"SVR\", label=\"(Test)\")\n",
    "image_path   = plot_predictions_lm(y_test, y_test_pred, model_name=\"SVR\", label=\"(Test)\")\n",
    "save_model_results_to_db(\"SVR\", val_metrics, test_metrics, image_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b614ee9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n",
      "✅ Best hyperparameters:\n",
      "{'subsample': 0.8, 'n_estimators': 800, 'min_child_weight': 5, 'max_depth': 3, 'learning_rate': 0.1, 'gamma': 1, 'colsample_bytree': 1.0}\n",
      "\n",
      "📊 XGBRegressor Evaluation (Validation)\n",
      "MAE:  11.5506 €/MWh\n",
      "RMSE: 14.8838 €/MWh\n",
      "R²:   0.6697\n",
      "\n",
      "📊 XGBRegressor Evaluation (Test)\n",
      "MAE:  10.5434 €/MWh\n",
      "RMSE: 13.4748 €/MWh\n",
      "R²:   0.6100\n",
      "\n",
      "📸 Plot salvato: c:\\Users\\QT153ZL\\OneDrive - EY\\Desktop\\electricity-price-forecasting\\images\\XGBRegressor.png\n",
      "✅ Results saved for XGBRegressor\n"
     ]
    }
   ],
   "source": [
    "# === IMPORTS ===\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import RandomizedSearchCV, TimeSeriesSplit\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# === 1. Parse 'date' column ===\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "\n",
    "# === 2. Temporal split: Train (<=2022), Validation (2023), Test (2024) ===\n",
    "train_df = df[df[\"date\"].dt.year <= 2022].copy()\n",
    "val_df   = df[df[\"date\"].dt.year == 2023].copy()\n",
    "test_df  = df[df[\"date\"].dt.year == 2024].copy()\n",
    "\n",
    "X_train = train_df.drop(columns=[\"target_pun\", \"date\"])\n",
    "y_train = train_df[\"target_pun\"]\n",
    "X_val   = val_df.drop(columns=[\"target_pun\", \"date\"])\n",
    "y_val   = val_df[\"target_pun\"]\n",
    "X_test  = test_df.drop(columns=[\"target_pun\", \"date\"])\n",
    "y_test  = test_df[\"target_pun\"]\n",
    "\n",
    "# === 3. Hyperparameter grid ===\n",
    "param_grid = {\n",
    "    \"n_estimators\": [300, 500, 800, 1000],\n",
    "    \"learning_rate\": [0.01, 0.03, 0.05, 0.1],\n",
    "    \"max_depth\": [3, 4, 5, 6, 8],\n",
    "    \"subsample\": [0.6, 0.8, 1.0],\n",
    "    \"colsample_bytree\": [0.6, 0.8, 1.0],\n",
    "    \"gamma\": [0, 1, 5],\n",
    "    \"min_child_weight\": [1, 3, 5]\n",
    "}\n",
    "\n",
    "# === 4. Base model ===\n",
    "base_model = XGBRegressor(\n",
    "    objective=\"reg:squarederror\",\n",
    "    random_state=42,\n",
    "    early_stopping_rounds=30,\n",
    "    eval_metric=\"mae\",\n",
    "    verbosity=0\n",
    ")\n",
    "\n",
    "# === 5. TimeSeriesSplit for time-aware cross-validation ===\n",
    "tscv = TimeSeriesSplit(n_splits=3)\n",
    "\n",
    "# === 6. RandomizedSearchCV with early stopping using validation set ===\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=base_model,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=30,\n",
    "    scoring=\"neg_mean_absolute_error\",\n",
    "    cv=tscv,\n",
    "    verbose=1,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# === 7. Fit model on training set with validation for early stopping ===\n",
    "random_search.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# === 8. Retrieve best model ===\n",
    "best_model = random_search.best_estimator_\n",
    "print(\"✅ Best hyperparameters:\")\n",
    "print(random_search.best_params_)\n",
    "print()\n",
    "\n",
    "# === 9. Predict on validation and test sets ===\n",
    "y_val_pred  = best_model.predict(X_val)\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "\n",
    "# === 10. Evaluate and save results ===\n",
    "val_metrics  = evaluate(y_val, y_val_pred, model_name=\"XGBRegressor\", label=\"(Validation)\")\n",
    "test_metrics = evaluate(y_test, y_test_pred, model_name=\"XGBRegressor\", label=\"(Test)\")\n",
    "image_path   = plot_predictions(y_test, y_test_pred, model_name=\"XGBRegressor\", label=\"(Test)\")\n",
    "save_model_results_to_db(\"XGBRegressor\", val_metrics, test_metrics, image_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
